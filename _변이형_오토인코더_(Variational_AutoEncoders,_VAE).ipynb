{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_변이형 오토인코더 (Variational AutoEncoders, VAE).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Computer_Vision/blob/main/_%EB%B3%80%EC%9D%B4%ED%98%95_%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94_(Variational_AutoEncoders%2C_VAE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_60ssUVlU0"
      },
      "source": [
        "# 이미지 생성 모델\n",
        "\n",
        "- 이미지 잠재 공간에서 샘플링하여 완전히 새로운 이미지나 기존 이미지를 변형시키는 방식의 주요 기법\n",
        "  - 변이형 오토인코더(Variational AutoEncoders, VAE)\n",
        "  \n",
        "  - 적대적 생성 네트워크(Generative Adversarial Networks, GAN)\n",
        "\n",
        "- 잠재 공간의 한 포인트를 입력으로 받아 이미지(픽셀의 그리드)를 출력하는 모듈을 VAE에서는 디코더(decoder)라고 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G-2CNkNYvZI"
      },
      "source": [
        "## 잠재 공간(Latent Space)\n",
        "\n",
        "<img src=\"https://images.deepai.org/converted-papers/2007.08383/x1.png\">\n",
        "\n",
        "<sub>[이미지 출처] https://deepai.org/publication/deep-learning-in-protein-structural-modeling-and-design</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM5AhdH7AGgf"
      },
      "source": [
        "# 변이형 오토인코더(Variational AutoEncoders, VAE)\n",
        "\n",
        "- 입력 이미지를 잠재 공간의 고정된 코딩으로 압축하는 대신  \n",
        "  이미지를 어떤 통계 분포의 파라미터로 변환 \n",
        "  \n",
        "- 평균과 분산 파라미터를 사용하여 이 분포에서 무작위로 하나의 샘플을 추출\n",
        "\n",
        "- 해당 샘플을 디코딩하여 원본 입력으로 복원\n",
        "\n",
        "- 위 과정은 안정성을 향상, 잠재 공간 어디에서든 의미있는 표현을 인코딩하게 함\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/variationalautoencoder-170601084514/95/variational-autoencoder-21-638.jpg?cb=1496306885\">\n",
        "\n",
        "  <sub>[이미지 출력] https://www.slideshare.net/ssuser06e0c5/variational-autoencoder-76552518</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- VAE의 훈련\n",
        "\n",
        "  - 디코딩된 샘플이 원본 입력과 동일하도록 만드는 재구성 손실(reconstruction loss)\n",
        "\n",
        "  - 잠재 공간을 잘 형성하고 훈련 데이터에 과적합을 줄이는 규제 손실(regularization loss)\n",
        "\n",
        "- VAE 구현의 pseudocode\n",
        "\n",
        "      z_mean, z_log_var = encoder(input_img)\n",
        "      \n",
        "      z = z_mean + exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "      recontructed_img = decoder(z)\n",
        "\n",
        "      model = Model(input_img, reconstructed_img)\n",
        "\n",
        "      재구성 손실과 규제 손실을 사용하여 훈련\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6TPr96HOE2b"
      },
      "source": [
        "# Convolutional VAE\n",
        "\n",
        "- MNIST Dataset\n",
        "\n",
        "- 코드 참조 : https://www.tensorflow.org/tutorials/generative/cvae?hl=ko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## 모듈 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-JuIu2N_SQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defb79ca-2850-4169-eb3e-3d7dcfb5c9c1"
      },
      "source": [
        "!pip install tensorflow-probability\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (0.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.19.5)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.19.5)\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-7f2ijk6_\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-7f2ijk6_\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.13)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.14->tensorflow-docs==0.0.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=157855 sha256=8a8a92f3f2b0df80f0663613b9b5c5ac6bc4052256615897e9c91bfe5f4ea0e2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ttr8bo7/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, Conv2D, InputLayer\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4fYMGxGhrna"
      },
      "source": [
        "(train_images , _) , (test_images , _ ) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhIG4lijPiAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f756c9e-cc23-47f2-ee2e-37e066001c23"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSIJQvcbPZ9z"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFC2ghIdiZYE"
      },
      "source": [
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Me98uqPckY"
      },
      "source": [
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eND2fTiPhmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e547a3-0da8-4509-d498-c93a2102e3c3"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "source": [
        "train_size = 60000\n",
        "batch_size = 32\n",
        "test_size = 10000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIGN6ouoQxt3"
      },
      "source": [
        "## tf.data 를 사용하여 데이터 일괄 처리 및 섞기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yKCCQOoJ7cn"
      },
      "source": [
        "train_dataset = (Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## 인코더, 디코더 모델 구성\n",
        "\n",
        "- VAE 예제에서는 인코더 및 디코더 네트워크에 두 개의 작은 ConvNet을 사용\n",
        "\n",
        "- 자세한 네트워크 구성 설명은 링크 참조\n",
        " \n",
        "  - https://www.tensorflow.org/tutorials/generative/cvae?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGLbvBEmjK0a"
      },
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CVAE , self).__init__()\n",
        "\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = Sequential([InputLayer(input_shape = (28,28,1)),\n",
        "                               Conv2D(filters = 32, kernel_size = 3,\n",
        "                                      strides = (2, 2), activation = 'relu'),\n",
        "                               Conv2D(filters = 64, kernel_size = 3,\n",
        "                                      strides = (2, 2), activation = 'relu'),\n",
        "                               Flatten(),\n",
        "                               Dense(latent_dim + latent_dim)])\n",
        "    \n",
        "    self.decoder = Sequential([InputLayer(input_shape = (latent_dim,)),\n",
        "                               Dense(units = 7*7*32 , activation = 'relu'),\n",
        "                               Reshape(target_shape = (7, 7, 32)),\n",
        "                               Conv2DTranspose(filters=64, kernel_size = 3,\n",
        "                                               strides = 2, padding = 'same',\n",
        "                                               activation = 'relu'),\n",
        "                               Conv2DTranspose(filters = 64, kernel_size = 3,\n",
        "                                               strides = 2, padding = 'same', \n",
        "                                               activation = 'relu'),\n",
        "                               Conv2DTranspose(filters = 1, kernel_size = 3,\n",
        "                                               strides =1 , padding = 'same')])\n",
        "    \n",
        "    def sample(self ,eps = None):\n",
        "      if eps is None:\n",
        "        eps = tf.random.normal(shape = (100 ,self.latent_dim))\n",
        "      return self.decode(eps, apply_sigmoid = True)\n",
        "\n",
        "    def encode(self, x):\n",
        "      mean, logvar = tf.split(self.encoder(x), num_or_size_splits = 2, axis = 1)\n",
        "\n",
        "    \n",
        "    def reparameterize(self, mean, logvar):\n",
        "      eps = tf.random.normal(shape = mean.shape)\n",
        "      return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid = False):\n",
        "      logits = self.decoder(z)\n",
        "\n",
        "      if apply_sigmoid:\n",
        "        probs = tf.sigmoid(logits)\n",
        "        return probs\n",
        "      \n",
        "      return probs\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## 손실 함수 및 최적화 프로그램 정의\n",
        "\n",
        "- VAE는 한계 로그 우도에서 증거 하한 (ELBO)을 최대화하여 학습\n",
        "\n",
        "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
        "\n",
        "- 실제로 우리는이 기대치의 단일 샘플 Monte Carlo 추정치를 최적화\n",
        "\n",
        "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yu0T6zZQ2yn"
      },
      "source": [
        "optimizer = Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis = 1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum( -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis = raxis)\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean,logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits = logit, labels = x)\n",
        "  logpx_z = tf.reduce_sum(cross_ent, axis = [1,2,3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "\n",
        "  return -tf.reduce_mean(logpx_z +logpz - logqz_x)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## 모델 학습 및 이미지 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvWlFXs2RCkN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swCyrbqQQ-Ri"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPRuEWrTRKHS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWuV_YBU_Fo"
      },
      "source": [
        "## 학습 시각화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "- 마지막 훈련 스텝에서 생성 된 이미지 표"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfO5wCdclHGL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "- 저장된 모든 이미지의 애니메이션 GIF 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZqAEtdqUmJF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeunRU6TSumT"
      },
      "source": [
        "- 잠재 공간에서 2D 다양한 숫자 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "mNcaaYPBS3mj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ZG69QCZnGY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}